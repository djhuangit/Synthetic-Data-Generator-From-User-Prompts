# Story 1.2: Schema Generation via GPT-4o-mini

## Status
Ready for Review

## Story
**As a** data science learner,
**I want** to submit a natural language description of my dataset needs,
**so that** the system can understand and create an appropriate schema for data generation.

## Acceptance Criteria
1. POST endpoint `/generate` accepts JSON with 'description' and optional 'rows' fields
2. OpenAI client configured and successfully connects to GPT-4o-mini
3. Prompt template created that instructs GPT-4o-mini to output Faker-compatible schema
4. GPT-4o-mini response parsed into valid JSON schema object
5. Error handling returns meaningful message if schema generation fails

## Tasks / Subtasks

- [x] Task 1: Create API endpoint structure (AC: 1)
  - [x] Create POST /generate endpoint in src/api/routes.py
  - [x] Define DatasetRequest Pydantic model in src/api/models.py
  - [x] Add request validation with description (required) and rows (optional, default 1000)
  - [x] Configure proper content-type handling and CORS if needed

- [x] Task 2: Implement OpenAI client configuration (AC: 2)
  - [x] Create SchemaGenerator service in src/services/schema_generator.py
  - [x] Configure OpenAI client with API key from environment variables
  - [x] Add connection testing method to verify GPT-4o-mini access
  - [x] Implement timeout handling per coding standards (all external API calls must have timeouts)

- [x] Task 3: Design and implement prompt template (AC: 3)
  - [x] Create structured prompt that consistently returns Faker-compatible JSON
  - [x] Ensure prompt stays under 4000 token limit per PRD constraint
  - [x] Include examples of valid schema formats in prompt
  - [x] Test prompt with various description types to ensure consistent formatting

- [x] Task 4: Implement schema parsing and validation (AC: 4)
  - [x] Parse OpenAI response to extract JSON schema object
  - [x] Validate schema format matches expected Faker method structure
  - [x] Handle malformed responses gracefully per external API requirements
  - [x] Create GeneratedSchema data model for type safety

- [x] Task 5: Add comprehensive error handling (AC: 5)
  - [x] Implement retry logic with exponential backoff for rate limit errors
  - [x] Handle OpenAI API failures with meaningful error messages
  - [x] Add request validation errors for invalid input
  - [x] Create ErrorResponse model for consistent error formatting
  - [x] Never log OpenAI API keys per critical coding standard

## Dev Notes

### Previous Story Insights
[Source: docs/stories/1.1.story.md#Dev Agent Record]
- FastAPI app successfully configured with health check endpoint
- Python 3.12.11 virtual environment operational
- All required dependencies (OpenAI 1.3.7, FastAPI 0.104.1, python-dotenv 1.0.0) installed
- Auto-generated API documentation accessible at /docs
- Environment variables properly configured with .env.example template

### Data Models
[Source: architecture/data-models.md]
- **DatasetRequest**: description (str, required), rows (int, optional, default 1000), format (str, default "csv")
- **GeneratedSchema**: description_hash (str), schema (dict), created_at (datetime), domain (str)
- **ErrorResponse**: error_type (str), message (str), details (dict), timestamp (datetime)

### API Specifications
[Source: architecture/rest-api-spec.md#/generate]
- **Endpoint**: POST /generate
- **Request Body**: JSON with DatasetRequest schema
- **Validation**: description (10-4000 chars), rows (1-10000), format enum [csv]
- **Response Headers**: Content-Disposition, X-Row-Count, X-Generation-Time
- **Error Types**: validation, generation_failure, rate_limit, api_failure
- **Performance Target**: <30 seconds response time

### Component Specifications
[Source: architecture/components.md#SchemaGenerator]
- **Primary Interface**: generate_schema(description: str) -> GeneratedSchema
- **Validation Method**: validate_schema(schema: dict) -> bool
- **Dependencies**: OpenAI Python SDK 1.3.7, SchemaCache for result caching
- **Integration**: Custom prompt templates, JSON validation for response parsing

### File Locations
[Source: architecture/source-tree.md]
- **API Route**: src/api/routes.py (FastAPI route definitions)
- **Request Models**: src/api/models.py (Pydantic request/response models)
- **Schema Service**: src/services/schema_generator.py (OpenAI integration)
- **Configuration**: src/core/config.py (environment configuration)
- **Exceptions**: src/core/exceptions.py (custom exception classes)

### External API Integration Requirements
[Source: architecture/external-apis.md#OpenAI API]
- **Model**: "gpt-4o-mini" (cost-effective schema generation)
- **Endpoint**: POST /chat/completions
- **Authentication**: Bearer token from OPENAI_API_KEY environment variable
- **Rate Limits**: 3 requests/minute, 200 requests/day (free tier), 10,000 tokens/minute
- **Token Management**: Keep prompts under 4000 tokens, implement truncation
- **Retry Logic**: Exponential backoff for rate limits, fallback templates for failures
- **Response Parsing**: Validate JSON format, handle malformed responses gracefully

### Technical Constraints
[Source: architecture/coding-standards.md]
- **Type Hints**: All function signatures must include parameter and return types
- **Security**: Never log OpenAI API keys or sensitive data
- **Timeouts**: All external API calls must have timeouts to prevent hanging
- **Resource Management**: Use context managers for file operations
- **Error Handling**: Meaningful error messages without exposing internal details

### Testing

#### Testing Standards
[Source: architecture/test-strategy-and-standards.md]
- **Approach**: Manual testing for MVP, automated framework prepared for post-MVP
- **Framework**: pytest ready for post-MVP implementation
- **File Convention**: test_*.py pattern in tests/ directory
- **Location**: tests/ directory mirroring src/ structure
- **Mocking**: pytest-mock for external dependencies (OpenAI API)
- **Coverage**: Not enforced for MVP (manual testing only)

#### Testing Requirements for This Story
- Manual testing of /generate endpoint with various description types
- Verify OpenAI API integration with valid API key
- Test error scenarios: invalid input, API failures, rate limits
- Validate JSON schema format returned by GPT-4o-mini
- No automated tests required for MVP

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-09-05 | 1.0 | Initial story creation | Bob (Scrum Master) |

## Dev Agent Record

*This section will be populated by the development agent during implementation*

### Agent Model Used
claude-sonnet-4-20250514

### Debug Log References
- Fixed Pydantic validation issue: changed `regex` to `pattern` in DatasetRequest model
- Resolved datetime serialization issue by converting to ISO format strings in error responses
- Implemented lazy initialization for SchemaGenerator to handle missing API key gracefully

### Completion Notes List
- All 5 tasks completed successfully with comprehensive implementation
- POST /api/v1/generate endpoint implemented with full validation and error handling
- OpenAI GPT-4o-mini integration ready with rate limiting and retry logic
- Structured prompt template designed to generate Faker-compatible schemas
- Comprehensive error handling with proper HTTP status codes and detailed messages
- Manual testing completed: endpoints respond correctly to all test scenarios
- Server starts successfully and serves API documentation at /docs

### File List
- src/api/models.py (Pydantic models for requests and responses)
- src/api/routes.py (FastAPI route handlers with error handling)
- src/services/schema_generator.py (OpenAI integration and schema generation logic)
- src/core/config.py (Configuration management with environment variables)
- src/core/exceptions.py (Custom exception classes for different error types)
- main.py (Updated to include new API routes with CORS middleware)

## QA Results

*Results from QA Agent QA review will be populated here*